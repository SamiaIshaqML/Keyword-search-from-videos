{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisor’s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.69)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.69 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.34.69)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.69->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (1.22.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (2.34.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (69.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=e2412478a0d3dea6676966465afb8de1f6e37bb26ff2e34e76868b8c5f5d3456\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n",
      "Successfully built moviepy\n",
      "Installing collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "def convert(src_name, dst_name):\n",
    "    video = VideoFileClip(src_name)\n",
    "    video.audio.write_audiofile(dst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'aws-tc-largeobjects'\n",
    "list_file_names = []\n",
    "pref = 'CUR-TF-200-ACMNLP-1/video'\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=pref)\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        list_file_names.append(obj['Key'])\n",
    "    \n",
    "    #cleaning file names\n",
    "    cleaned_file_names = []\n",
    "    for i in range(len(list_file_names)):\n",
    "        s = list_file_names[i].split('/')\n",
    "        cleaned_file_names.append(s[-1])\n",
    "    #print(cleaned_file_names)\n",
    "    '''\n",
    "    #converting the video files to audio to reduce bytes processed\n",
    "    for i in range(len(list_file_names)):\n",
    "        file_name = cleaned_file_names[i]\n",
    "        \n",
    "        res = s3.get_object(Bucket=bucket_name, Key=list_file_names[i])\n",
    "        aud = res['Body'].read()\n",
    "        file_size = res['ContentLength']\n",
    "        print(file_size)\n",
    "        \n",
    "        #conversion\n",
    "        \n",
    "        s3.download_file(bucket_name, list_file_names[i], \"videos/temp.mp4\")\n",
    "        audio_name = file_name.split('.')\n",
    "        audio_name = audio_name[0]\n",
    "        audio_name = audio_name + \".mp3\"\n",
    "        new = convert(\"videos/temp.mp4\", \"audios/\"+ audio_name)'''\n",
    "else:\n",
    "    print(\"Empty Folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8602270\n"
     ]
    }
   ],
   "source": [
    "#observing the change in size of file\n",
    "import os\n",
    "print(os.path.getsize(\"audios/Mod04_Sect02_part1.mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = \"audios\"\n",
    "import os\n",
    "for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        if file_name.lower().endswith(('.mp3')):\n",
    "            files.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audios/Mod04_Sect02_part1.mp3', 'audios/Mod06_Sect01.mp3', 'audios/Mod03_WrapUp.mp3', 'audios/Mod02_Sect01.mp3', 'audios/Mod03_Sect03_part1.mp3', 'audios/Mod05_Sect02_part2.mp3', 'audios/Mod03_Sect06.mp3', 'audios/Mod02_Sect04.mp3', 'audios/Mod03_Sect03_part3.mp3', 'audios/Mod03_Sect02_part2.mp3', 'audios/Mod05_WrapUp_ver2.mp3', 'audios/Mod02_Intro.mp3', 'audios/Mod03_Sect05.mp3', 'audios/Mod03_Sect08.mp3', 'audios/Mod03_Sect04_part3.mp3', 'audios/Mod04_Intro.mp3', 'audios/Mod03_Sect04_part2.mp3', 'audios/Mod04_Sect01.mp3', 'audios/Mod05_Intro.mp3', 'audios/Mod05_Sect03_part1.mp3', 'audios/Mod03_Sect07_part2.mp3', 'audios/Mod01_Course Overview.mp3', 'audios/Mod04_Sect02_part2.mp3', 'audios/Mod03_Sect02_part1.mp3', 'audios/Mod06_WrapUp.mp3', 'audios/Mod05_Sect03_part4_ver2.mp3', 'audios/Mod05_Sect03_part2.mp3', 'audios/Mod05_Sect02_part1_ver2.mp3', 'audios/Mod03_Sect04_part1.mp3', 'audios/Mod03_Sect07_part1.mp3', 'audios/Mod03_Sect01.mp3', 'audios/Mod03_Intro.mp3', 'audios/Mod04_Sect02_part3.mp3', 'audios/Mod04_WrapUp.mp3', 'audios/Mod02_Sect03.mp3', 'audios/Mod05_Sect01_ver2.mp3', 'audios/Mod03_Sect03_part2.mp3', 'audios/Mod06_Intro.mp3', 'audios/Mod07_Sect01.mp3', 'audios/Mod02_WrapUp.mp3', 'audios/Mod02_Sect05.mp3', 'audios/Mod03_Sect02_part3.mp3', 'audios/Mod03_Sect07_part3.mp3', 'audios/Mod02_Sect02.mp3', 'audios/Mod06_Sect02.mp3', 'audios/Mod05_Sect03_part3.mp3']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm_watson\n",
      "  Downloading ibm-watson-8.0.0.tar.gz (398 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.3/398.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ibm_watson) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ibm_watson) (2.8.2)\n",
      "Requirement already satisfied: websocket-client>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ibm_watson) (1.7.0)\n",
      "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6 (from ibm_watson)\n",
      "  Downloading ibm-cloud-sdk-core-3.19.2.tar.gz (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting urllib3<3.0.0,>=2.1.0 (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting PyJWT<3.0.0,>=2.8.0 (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.5.3->ibm_watson) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.0->ibm_watson) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.0->ibm_watson) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.0->ibm_watson) (2024.2.2)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Building wheels for collected packages: ibm_watson, ibm-cloud-sdk-core\n",
      "  Building wheel for ibm_watson (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm_watson: filename=ibm_watson-8.0.0-py3-none-any.whl size=401037 sha256=1f934d1f72074f6c5e58ac2d49c1673dee1d9d5552db1cd6406008d87b5fbb5f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/3b/7f/40/3601b4f434eb462a9f46e24b9dd8c96881e6e913a18cc904f9\n",
      "  Building wheel for ibm-cloud-sdk-core (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.19.2-py3-none-any.whl size=98827 sha256=4c6a600523105a6f15d3e1ba1b28f3e71cf02f571e551d311509ff803d9fb283\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/05/db/f544eb28b85089bf6cf29cb9e30f56b471bf59d56a46c92519\n",
      "Successfully built ibm_watson ibm-cloud-sdk-core\n",
      "Installing collected packages: urllib3, PyJWT, ibm-cloud-sdk-core, ibm_watson\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.0 which is incompatible.\n",
      "sphinx 7.2.6 requires docutils<0.21,>=0.18.1, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyJWT-2.8.0 ibm-cloud-sdk-core-3.19.2 ibm_watson-8.0.0 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apikey = 'rua-MmGloTNhTPc2rrPrCeEyZKqc3w7l691MxcLI_amV'\n",
    "url = 'https://api.au-syd.speech-to-text.watson.cloud.ibm.com/instances/be7a1e87-d5e6-4e4f-a08a-a5070095f974'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator(apikey)\n",
    "stt = SpeechToTextV1(authenticator = authenticator)\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result_index': 0, 'results': [{'final': True, 'alternatives': [{'transcript': 'hi and welcome to marginal four of aws academy machine learning ', 'confidence': 0.83}]}, {'final': True, 'alternatives': [{'transcript': \"in this module we're going to look at forecasting \", 'confidence': 0.92}]}, {'final': True, 'alternatives': [{'transcript': 'will start with an introduction to forecasting and look at how time series data is different from other kinds of data ', 'confidence': 0.95}]}, {'final': True, 'alternatives': [{'transcript': \"then we're going to look at amazon forecast a service that helps you simplify building forecasts \", 'confidence': 0.95}]}, {'final': True, 'alternatives': [{'transcript': \"at the end of this module you'll be able to describe the business problem solved with amazon forecast \", 'confidence': 0.96}]}, {'final': True, 'alternatives': [{'transcript': 'describe the challenges of working with time series data ', 'confidence': 0.96}]}, {'final': True, 'alternatives': [{'transcript': 'list the steps required to create a forecast by using amazon forecast ', 'confidence': 0.97}]}, {'final': True, 'alternatives': [{'transcript': 'and use amazon forecast to make a prediction ', 'confidence': 0.95}]}, {'final': True, 'alternatives': [{'transcript': 'see you in the next video ', 'confidence': 0.91}]}]}\n"
     ]
    }
   ],
   "source": [
    "res = stt.recognize(audio=open(files[15], 'rb'), content_type='audio/mp3', model='en-US_Telephony', \\\n",
    "                           inactivity_timeout=360).get_result()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for filename in files:\n",
    "    res = stt.recognize(audio=open(filename, 'rb'), content_type='audio/mp3', model='en-US_Telephony', \\\n",
    "                       inactivity_timeout=360).get_result()\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#keeping each file's text at the index\n",
    "transcribed_text = {}\n",
    "for i in range(len(files)):\n",
    "    text = []\n",
    "    res = results[i]\n",
    "    r = res['results']\n",
    "    for j in range(len(r)):\n",
    "        lis = r[j]\n",
    "        s = lis['alternatives']\n",
    "        t = s[0]\n",
    "        v = t['transcript']\n",
    "        text.append(v)\n",
    "    text = ''.join(text)\n",
    "    transcribed_text[files[i]] = [text]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hi welcome back we'll continue exploring video analysis by reviewing how to create the test data set the final step before you train your model is to identify a test data set you will use this test data set to validate and evaluate the models performance you'll do this by performing an inference on the images in the test data set you'll then compare the results with the labeling information that's in the training data set you can create your own test data set alternatively you can use amazon recognition costume labels to split your training data set into two data sets by using an eighty twenty split this split means that eighty percent of the data is used for training and twenty percent is used for testing after you define the training and test data sets amazon recognition custom labels can automatically train the model for you the service automatically loads and inspects the data selects the correct machine learning algorithms trains a model and provides model performance metrics you're charged for the amount of time a model takes to train a data set that contains more images and labels will take longer to train when training's complete you evaluate the performance of the model during testing amazon recognition custom labels predicts if a test image contains a custom label the confidence score is a value that quantifies the certainty of the models prediction because this is a classification problem the results can be mapped to a confusion matrix with a true positive the model correctly predicts the presence of the custom label in the test image that is the predicting label is also a ground truth label for that image for example amazon recognition custom labels correctly returns a cat label when a cat is present in an image for a false positive the model incorrectly predicts the presence of a custom label in a test image that is the predicted label isn't a ground truth label for the image for example amazon recognition custom labels returns a cat label but there's no cat label in the ground true for that image for a false negative the model doesn't predict that a custom label is present in the image but the ground truth for that image includes this label for example amazon recognition custom labels doesn't return a cat custom label for an image that contains a cat with a true negative the model correctly predicts that a custom label isn't present in the test image for example amazon recognition custom labels doesn't return a cat label for an image that doesn't contain a cat the console provides access to true positive false positive and false negative values for each image in your test data set these prediction results are used to calculate the various metrics for each label and an aggregative metrics for your entire test set the same definitions apply to predictions that the model makes at the bounding box level with bounding boxes all metrics are calculated over each bounding box in each test image regardless of whether the boxes are prediction or ground truth to help you amazon recognition custom labels provides various metrics for example you can view summary metrics and evaluation metrics for each label it also provides precision metrics for each label and an average precision matric for the entire test data set precision is the proportion of ponds of results that were correctly classified amazon recognition custom labels provides average recall metrics for each label and an average recall metroic for the entire test data set recall is the fraction of your test set labels that were correctly classified using the previous example of cats that would be how many cats were correctly classified the service also provides an average model performance gore for each label and an average model performance gore for the entire test data set the f one score combines precision and recall together to give you just one number that quantifies the overall performance of a particular machine learning algerithm you might use the f one score when you have a class in balance but you also want to preserve the equality between precision and sensitivity a higher value means better model performance for both recall and precision if you're satisfied with the accuracy of your model you can start using it that's it for part three of this section we'll see you again for part four we will review how to evaluate and improve your model \"]\n"
     ]
    }
   ],
   "source": [
    "print(transcribed_text['audios/Mod05_Sect03_part3.mp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            file_names  \\\n",
      "0        audios/Mod04_Sect02_part1.mp3   \n",
      "1              audios/Mod06_Sect01.mp3   \n",
      "2              audios/Mod03_WrapUp.mp3   \n",
      "3              audios/Mod02_Sect01.mp3   \n",
      "4        audios/Mod03_Sect03_part1.mp3   \n",
      "5        audios/Mod05_Sect02_part2.mp3   \n",
      "6              audios/Mod03_Sect06.mp3   \n",
      "7              audios/Mod02_Sect04.mp3   \n",
      "8        audios/Mod03_Sect03_part3.mp3   \n",
      "9        audios/Mod03_Sect02_part2.mp3   \n",
      "10        audios/Mod05_WrapUp_ver2.mp3   \n",
      "11              audios/Mod02_Intro.mp3   \n",
      "12             audios/Mod03_Sect05.mp3   \n",
      "13             audios/Mod03_Sect08.mp3   \n",
      "14       audios/Mod03_Sect04_part3.mp3   \n",
      "15              audios/Mod04_Intro.mp3   \n",
      "16       audios/Mod03_Sect04_part2.mp3   \n",
      "17             audios/Mod04_Sect01.mp3   \n",
      "18              audios/Mod05_Intro.mp3   \n",
      "19       audios/Mod05_Sect03_part1.mp3   \n",
      "20       audios/Mod03_Sect07_part2.mp3   \n",
      "21    audios/Mod01_Course Overview.mp3   \n",
      "22       audios/Mod04_Sect02_part2.mp3   \n",
      "23       audios/Mod03_Sect02_part1.mp3   \n",
      "24             audios/Mod06_WrapUp.mp3   \n",
      "25  audios/Mod05_Sect03_part4_ver2.mp3   \n",
      "26       audios/Mod05_Sect03_part2.mp3   \n",
      "27  audios/Mod05_Sect02_part1_ver2.mp3   \n",
      "28       audios/Mod03_Sect04_part1.mp3   \n",
      "29       audios/Mod03_Sect07_part1.mp3   \n",
      "30             audios/Mod03_Sect01.mp3   \n",
      "31              audios/Mod03_Intro.mp3   \n",
      "32       audios/Mod04_Sect02_part3.mp3   \n",
      "33             audios/Mod04_WrapUp.mp3   \n",
      "34             audios/Mod02_Sect03.mp3   \n",
      "35        audios/Mod05_Sect01_ver2.mp3   \n",
      "36       audios/Mod03_Sect03_part2.mp3   \n",
      "37              audios/Mod06_Intro.mp3   \n",
      "38             audios/Mod07_Sect01.mp3   \n",
      "39             audios/Mod02_WrapUp.mp3   \n",
      "40             audios/Mod02_Sect05.mp3   \n",
      "41       audios/Mod03_Sect02_part3.mp3   \n",
      "42       audios/Mod03_Sect07_part3.mp3   \n",
      "43             audios/Mod02_Sect02.mp3   \n",
      "44             audios/Mod06_Sect02.mp3   \n",
      "45       audios/Mod05_Sect03_part3.mp3   \n",
      "\n",
      "                                                 text  \n",
      "0   [hi and welcome back this is section two and w...  \n",
      "1   [will get started by reviewing what natural la...  \n",
      "2   [it's now time to review the monul and wrap up...  \n",
      "3   [i and welcome to section one in this section ...  \n",
      "4   [hi i'm welcome back this is section three and...  \n",
      "5   [hi welcome back we'll continue exploring imag...  \n",
      "6   [i am walking back this is section six and we'...  \n",
      "7   [welcome back in this section we'll look at so...  \n",
      "8   [hi welcome back now we'll review how to find ...  \n",
      "9   [hi welcome back we'll continue exploring data...  \n",
      "10  [it's now time to summarise some of the main p...  \n",
      "11  [hi and welcome to module two of aws academy m...  \n",
      "12  [hi welcome back to module three this is secti...  \n",
      "13  [hi and welcome back to margil three this is s...  \n",
      "14  [hi welcome back we'll continue exploring feat...  \n",
      "15  [hi and welcome to marginal four of aws academ...  \n",
      "16  [i welcome back we'll continue exploring featu...  \n",
      "17  [hi and welcome to section one we'll get start...  \n",
      "18  [welcome back to aws academy machine learning ...  \n",
      "19  [in this section we'll look at preparing custo...  \n",
      "20  [hi welcome back we'll continue exploring how ...  \n",
      "21  [hi and welcome to amazon academy machine lear...  \n",
      "22  [hi welcome back will continue exploring wrang...  \n",
      "23  [hi welcome back we're now going to look at a ...  \n",
      "24  [welcome back it's now time to review the monu...  \n",
      "25  [hi welcome back we'll continue exploring vide...  \n",
      "26  [hi welcome back will continue exploring video...  \n",
      "27  [welcome back in this section will explore ima...  \n",
      "28  [i am welcome to section for in this section w...  \n",
      "29  [i welcome back to marginal three in this sect...  \n",
      "30  [hi and welcome back to margible three this is...  \n",
      "31  [welcome back to aws academy machine learning ...  \n",
      "32  [hi and welcome back in this section we'll loo...  \n",
      "33  [hi walking back it's now time to review the m...  \n",
      "34  [hi i'm welcome back this is section three and...  \n",
      "35  [hi welcome back this is section one and we're...  \n",
      "36  [hi welcome back we'll continue exploring how ...  \n",
      "37  [hi and welcome to marginal six of aws academy...  \n",
      "38  [welcome to margial seven course wrap up congr...  \n",
      "39  [it's now time to review the margial here are ...  \n",
      "40  [i welcome back this is section five and we're...  \n",
      "41  [hi welcome back we'll continue exploring data...  \n",
      "42  [hi welcome back we'll continue exploring how ...  \n",
      "43  [hi i'm working back in this section we're goi...  \n",
      "44  [welcome back in this section will review five...  \n",
      "45  [hi welcome back we'll continue exploring vide...  \n"
     ]
    }
   ],
   "source": [
    "#saving all of the transcribed data in a csv file\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(transcribed_text.items()), columns=['file_names', 'text'])\n",
    "print(df)\n",
    "\n",
    "csv = 'transcribed_text.csv'\n",
    "\n",
    "df.to_csv(csv, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                     file_names  \\\n",
      "0           0  audios/Mod04_Sect02_part1.mp3   \n",
      "1           1        audios/Mod06_Sect01.mp3   \n",
      "2           2        audios/Mod03_WrapUp.mp3   \n",
      "3           3        audios/Mod02_Sect01.mp3   \n",
      "4           4  audios/Mod03_Sect03_part1.mp3   \n",
      "\n",
      "                                                text  \n",
      "0  [\"hi and welcome back this is section two and ...  \n",
      "1  [\"will get started by reviewing what natural l...  \n",
      "2  [\"it's now time to review the monul and wrap u...  \n",
      "3  [\"i and welcome to section one in this section...  \n",
      "4  [\"hi i'm welcome back this is section three an...  \n"
     ]
    }
   ],
   "source": [
    "#load the csv file as a dataframe for preprocessing\n",
    "import pandas as pd \n",
    "df = pd.read_csv('transcribed_text.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def removal_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def text_preprocessing(str):\n",
    "    # normalization\n",
    "    lowercase = str.lower()\n",
    "    rm_numbers = re.sub(r'\\d+','', lowercase)\n",
    "    rm_punc = re.sub(r'[^\\w\\s]','', rm_numbers)\n",
    "    rm_wspace = rm_punc.strip()\n",
    "    no_stop_words = removal_stopwords(rm_wspace)\n",
    "\n",
    "    #  #lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_string = lemmatizer.lemmatize(no_stop_words)\n",
    "\n",
    "    return lemmatized_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_text = df['text'].apply(text_preprocessing)\n",
    "df['preprocessed_text'] = preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (2.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (69.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.22.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return doc.ents\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords = df['text'].apply(extract_keywords)\n",
    "df['keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ((two), (third), (some, day), (the, month), (t...\n",
      "1     ((next, language), (english), (one), (first), ...\n",
      "2                                                    ()\n",
      "3     ((first), (every, year), (twenty, four, seven)...\n",
      "4     ((three), (one), (csv), (java), (japanese), (t...\n",
      "5     ((two), (first), (three), (gat), (seconds), (r...\n",
      "6     ((six), (first), (diplomas), (tens, of, thousa...\n",
      "7     ((today), (first), (jupiter), (jupiter), (line...\n",
      "8     ((one), (two), (two), (zero), (two), (one), (f...\n",
      "9     ((three), (first), (three), (jupiter), (three)...\n",
      "10                                                   ()\n",
      "11                                     ((two), (first))\n",
      "12    ((three), (five), (first), (three), (first), (...\n",
      "13    ((three), (eight), (first), (second), (third),...\n",
      "14    ((two), (first), (second), (two), (two), (two)...\n",
      "15                                            ((four),)\n",
      "16    ((between, two, and, eight), (california), (th...\n",
      "17    ((two), (first), (one), (second), (more, than,...\n",
      "18       ((five), (today), (the, end, of, this, month))\n",
      "19    ((one), (tens, of, millions), (eight), (billio...\n",
      "20    ((two), (two), (hundreds), (first), (sixty, pe...\n",
      "21    ((amazon, academy, machine, learning), (first)...\n",
      "22    ((the, end, of, a, quarter), (the, fourth, qua...\n",
      "23    ((one), (brad, street), (uci), (two), (two), (...\n",
      "24                                ((the, next, month),)\n",
      "25    ((first), (between, two), (first), (first), (t...\n",
      "26    ((three), (three), (at, least, two), (at, leas...\n",
      "27    ((two), (java), (pypon, p, h, p, dot, net), (t...\n",
      "28    ((two), (first), (second), (two), (three), (fo...\n",
      "29              ((three), (two), (two), (first), (two))\n",
      "30    ((three), (section, two), (section, three), (s...\n",
      "31                                           ((three),)\n",
      "32    ((three), (first), (three), (ten, percent), (f...\n",
      "33                                                   ()\n",
      "34    ((three), (one), (one), (four), (three), (elev...\n",
      "35    ((three), (the, last, ten, years), (first), (t...\n",
      "36    ((first), (more, than, one), (two), (two), (on...\n",
      "37                                      ((six), (five))\n",
      "38    ((seven), (a, few, minutes), (every, three, ye...\n",
      "39                                           ((first),)\n",
      "40            ((five), (today), (abus), (one), (first))\n",
      "41                   ((three), (first), (section, two))\n",
      "42    ((between, zero), (fifty, percent), (roc), (on...\n",
      "43    ((three), (two), (first), (two), (one), (three...\n",
      "44    ((five), (two), (first), (two), (three), (the,...\n",
      "45    ((two), (eighty, twenty), (eighty, percent), (...\n",
      "Name: keywords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(all_videos, search_words):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vid_text_vector = vectorizer.fit_transform(all_videos)\n",
    "    search_vector = vectorizer.transform(search_words)\n",
    "    \n",
    "    #find the cosine simlairty between the searched word vector and videos\n",
    "    similarity_score = cosine_similarity(search_vector, vid_text_vector)\n",
    "    \n",
    "    #first i will store the indices of the score above 0.1 so i can track the video it is from\n",
    "    store_best_videos = {}\n",
    "    for i in range(len(similarity_score[0])):\n",
    "        if similarity_score[0][i] > 0.1:\n",
    "            store_best_videos[i] = similarity_score[0][i]\n",
    "    \n",
    "    #sorting the dictionary of best videos by similarity score - to get the most relevant results at top\n",
    "    sorted_bestvideos = {key: value for key, value in sorted(store_best_videos.items(), key=lambda item: item[1],reverse=True)}\n",
    "    \n",
    "    #return the text of those best videos - this was only for me to check if the videos being suggested are relevant\n",
    "    '''\n",
    "    for key, value in sorted_bestvideos.items():\n",
    "        print(all_videos[key])'''\n",
    "    return sorted_bestvideos\n",
    "        \n",
    "    \n",
    "\n",
    "#keywords = ['text']\n",
    "#search(df['text'].tolist(), keywords)\n",
    "#print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets) (8.22.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_list = df['file_names'].tolist()\n",
    "urls = []\n",
    "for i in range(len(files_list)):\n",
    "    splitone = files_list[i].split('/')\n",
    "    splittwo = splitone[1].split('.')\n",
    "    files_list[i] = splittwo[0] + '.mp4'\n",
    "                                 \n",
    "def find_videolink(search_word):\n",
    "    video_dict = search(df['text'].tolist(), search_word)\n",
    "    #print(video_dict)\n",
    "    temp_link = 'https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/'\n",
    "    for k,v in video_dict.items():\n",
    "        link = temp_link + files_list[k]\n",
    "        urls.append(link)\n",
    "    print(urls)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b558105aff794295921755a0c45a516e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='Search for the topic you wish to learn about and press enter')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8269fdc3c7b24cf982ef64e06009924b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='Input:', placeholder='Enter text for search')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text = widgets.HTML('Search for the topic you wish to learn about and press enter')\n",
    "\n",
    "    \n",
    "text_input = widgets.Text(\n",
    "    placeholder='Enter text for search',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Display the text input widget\n",
    "display(text)\n",
    "display(text_input)\n",
    "\n",
    "#after entering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word = [str(text_input.value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the following videos to learn more aboutimages\n",
      "['https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part1.mp4', 'https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part4_ver2.mp4', 'https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/Mod05_Sect01_ver2.mp4', 'https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part2.mp4', 'https://aws-tc-largeobjects.s3.amazonaws.com/CUR-TF-200-ACMNLP-1/video/Mod05_Sect02_part1_ver2.mp4']\n"
     ]
    }
   ],
   "source": [
    "print(\"Click on the following videos to learn more about\" + str(text_input.value))\n",
    "find_videolink(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
